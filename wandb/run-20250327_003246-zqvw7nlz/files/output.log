  0%|                                                                                               | 0/60 [00:00<?, ?it/s]C:\Users\zizha\anaconda3\envs\311\Lib\site-packages\torch\utils\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]


 17%|██████████████▎                                                                       | 10/60 [00:05<00:24,  2.01it/s]


 30%|█████████████████████████▊                                                            | 18/60 [00:09<00:21,  1.92it/s]



 52%|████████████████████████████████████████████▍                                         | 31/60 [00:15<00:14,  1.97it/s]


 65%|███████████████████████████████████████████████████████▉                              | 39/60 [00:19<00:11,  1.90it/s]



 85%|█████████████████████████████████████████████████████████████████████████             | 51/60 [00:25<00:04,  2.06it/s]


 98%|████████████████████████████████████████████████████████████████████████████████████▌ | 59/60 [00:29<00:00,  2.00it/s]
{'loss': 4.3513, 'grad_norm': 40.522552490234375, 'learning_rate': 9.259259259259259e-07, 'epoch': 8.64}
100%|██████████████████████████████████████████████████████████████████████████████████████| 60/60 [00:29<00:00,  2.00it/s]
INFO:__main__:Training completed successfully
INFO:__main__:Saving model
INFO:__main__:Generating caption for the first training image to evaluate the model
C:\Users\zizha\anaconda3\envs\311\Lib\site-packages\torch\utils\checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
INFO:__main__:Original caption: Closeup of bins of food that include broccoli and bread.
INFO:__main__:Generated caption: a detailed image showing broccoli and bread in a variety of containers one of the many different types of food in the food section of a & amp.
INFO:__main__:Model saved to models/vlm/gen_1_baseline
INFO:__main__:Training generation 2
INFO:__main__:Using checkpoint from models/vlm/gen_1_baseline
INFO:__main__:Found 100 images for training
INFO:__main__:Loaded 414113 captions from data/coco/annotations/captions_train2014.json
INFO:__main__:Found 100 images in data/vlm/train/images/real
INFO:__main__:Created dataset with 100 image-caption pairs for gen_2 using baseline mode
INFO:__main__:Using all 100 images for training in gen_2 with baseline mode
INFO:__main__:Loading model with aggressive memory optimizations
INFO:accelerate.utils.modeling:We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
INFO:__main__:Starting training for generation 2 with 10 epochs in baseline mode
  0%|                                                                                               | 0/60 [00:00<?, ?it/s]C:\Users\zizha\anaconda3\envs\311\Lib\site-packages\torch\utils\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]


 15%|█████████████                                                                          | 9/60 [00:04<00:25,  1.98it/s]



 37%|███████████████████████████████▌                                                      | 22/60 [00:11<00:17,  2.22it/s]


 50%|███████████████████████████████████████████                                           | 30/60 [00:14<00:14,  2.14it/s]


 63%|██████████████████████████████████████████████████████▍                               | 38/60 [00:18<00:10,  2.05it/s]



 85%|█████████████████████████████████████████████████████████████████████████             | 51/60 [00:25<00:04,  1.95it/s]


 97%|███████████████████████████████████████████████████████████████████████████████████▏  | 58/60 [00:28<00:01,  1.94it/s]
{'loss': 1.3253, 'grad_norm': 33.76884460449219, 'learning_rate': 0.0, 'epoch': 8.64}
100%|██████████████████████████████████████████████████████████████████████████████████████| 60/60 [00:30<00:00,  2.00it/s]
INFO:__main__:Training completed successfully
INFO:__main__:Saving model
INFO:__main__:Generating caption for the first training image to evaluate the model
Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.
C:\Users\zizha\anaconda3\envs\311\Lib\site-packages\torch\utils\checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
INFO:__main__:Original caption: Closeup of bins of food that include broccoli and bread.
INFO:__main__:Generated caption: a high resolution photo that shows some broccoli and bread in a bin - the. a _ … big
INFO:__main__:Model saved to models/vlm/gen_2_baseline
INFO:__main__:Training generation 3
INFO:__main__:Using checkpoint from models/vlm/gen_2_baseline
INFO:__main__:Found 100 images for training
INFO:__main__:Loaded 414113 captions from data/coco/annotations/captions_train2014.json
INFO:__main__:Found 100 images in data/vlm/train/images/real
INFO:__main__:Created dataset with 100 image-caption pairs for gen_3 using baseline mode
INFO:__main__:Using all 100 images for training in gen_3 with baseline mode
INFO:__main__:Loading model with aggressive memory optimizations
INFO:accelerate.utils.modeling:We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
INFO:__main__:Starting training for generation 3 with 10 epochs in baseline mode
  0%|                                                                                               | 0/60 [00:00<?, ?it/s]C:\Users\zizha\anaconda3\envs\311\Lib\site-packages\torch\utils\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]
  7%|█████▊                                                                                 | 4/60 [00:02<00:33,  1.69it/s]
 13%|███████████▌                                                                           | 8/60 [00:04<00:24,  2.10it/s]
 13%|███████████▌                                                                           | 8/60 [00:04<00:24,  2.10it/s]
 20%|█████████████████▏                                                                    | 12/60 [00:06<00:26,  1.81it/s]
 27%|██████████████████████▉                                                               | 16/60 [00:08<00:22,  1.95it/s]
 33%|████████████████████████████▋                                                         | 20/60 [00:10<00:22,  1.79it/s]
 33%|████████████████████████████▋                                                         | 20/60 [00:10<00:22,  1.79it/s]
 40%|██████████████████████████████████▍                                                   | 24/60 [00:12<00:18,  1.92it/s]
 47%|████████████████████████████████████████▏                                             | 28/60 [00:14<00:13,  2.31it/s]
 47%|████████████████████████████████████████▏                                             | 28/60 [00:14<00:13,  2.31it/s]
 52%|████████████████████████████████████████████▍                                         | 31/60 [00:16<00:15,  1.87it/s]
 60%|███████████████████████████████████████████████████▌                                  | 36/60 [00:18<00:11,  2.04it/s]
 65%|███████████████████████████████████████████████████████▉                              | 39/60 [00:20<00:11,  1.87it/s]
 65%|███████████████████████████████████████████████████████▉                              | 39/60 [00:20<00:11,  1.87it/s]
{'loss': 0.1594, 'grad_norm': 4.857583045959473, 'learning_rate': 1.8518518518518518e-05, 'epoch': 5.8}
 65%|███████████████████████████████████████████████████████▉                              | 39/60 [00:20<00:11,  1.87it/s]
 65%|███████████████████████████████████████████████████████▉                              | 39/60 [00:20<00:11,  1.87it/s]
{'loss': 0.0958, 'grad_norm': 3.4027538299560547, 'learning_rate': 9.259259259259259e-06, 'epoch': 7.16}
 65%|███████████████████████████████████████████████████████▉                              | 39/60 [00:20<00:11,  1.87it/s]
 65%|███████████████████████████████████████████████████████▉                              | 39/60 [00:20<00:11,  1.87it/s]
 65%|███████████████████████████████████████████████████████▉                              | 39/60 [00:20<00:11,  1.87it/s]
{'loss': 0.0862, 'grad_norm': 2.929943323135376, 'learning_rate': 0.0, 'epoch': 8.64}
INFO:__main__:Found 100 images for trainingent checkpointing. Setting `use_cache=False`... | 39/60 [00:20<00:11,  1.87it/s]
  3%|██▉                                                                                    | 2/60 [00:01<00:33,  1.74it/s]
 12%|██████████▏                                                                            | 7/60 [00:03<00:22,  2.40it/s]
 17%|██████████████▎                                                                       | 10/60 [00:05<00:26,  1.90it/s]
 17%|██████████████▎                                                                       | 10/60 [00:05<00:26,  1.90it/s]
 25%|█████████████████████▌                                                                | 15/60 [00:07<00:20,  2.16it/s]
 25%|█████████████████████▌                                                                | 15/60 [00:07<00:20,  2.16it/s]
 25%|█████████████████████▌                                                                | 15/60 [00:07<00:20,  2.16it/s]
{'loss': 0.0456, 'grad_norm': 0.787714421749115, 'learning_rate': 3.7037037037037037e-05, 'epoch': 2.96}
 25%|█████████████████████▌                                                                | 15/60 [00:07<00:20,  2.16it/s]
 25%|█████████████████████▌                                                                | 15/60 [00:07<00:20,  2.16it/s]
 25%|█████████████████████▌                                                                | 15/60 [00:07<00:20,  2.16it/s]
{'loss': 0.03, 'grad_norm': 0.43993449211120605, 'learning_rate': 2.777777777777778e-05, 'epoch': 4.32}
 25%|█████████████████████▌                                                                | 15/60 [00:07<00:20,  2.16it/s]
 25%|█████████████████████▌                                                                | 15/60 [00:07<00:20,  2.16it/s]
{'loss': 0.0205, 'grad_norm': 0.3981398344039917, 'learning_rate': 1.8518518518518518e-05, 'epoch': 5.8}
 25%|█████████████████████▌                                                                | 15/60 [00:07<00:20,  2.16it/s]
 25%|█████████████████████▌                                                                | 15/60 [00:07<00:20,  2.16it/s]
 25%|█████████████████████▌                                                                | 15/60 [00:07<00:20,  2.16it/s]
{'loss': 0.0135, 'grad_norm': 0.3000745475292206, 'learning_rate': 9.259259259259259e-06, 'epoch': 7.16}
 25%|█████████████████████▌                                                                | 15/60 [00:07<00:20,  2.16it/s]
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`... | 15/60 [00:07<00:20,  2.16it/s]
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`... | 15/60 [00:07<00:20,  2.16it/s]
{'loss': 0.0136, 'grad_norm': 0.3035208582878113, 'learning_rate': 0.0, 'epoch': 8.64}
{'train_runtime': 30.8722, 'train_samples_per_second': 32.392, 'train_steps_per_second': 1.943, 'train_loss': 0.032635381321112315, 'epoch': 8.64}
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`... | 15/60 [00:07<00:20,  2.16it/s]
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
INFO:__main__:Original caption: Closeup of bins of food that include broccoli and bread.
INFO:__main__:Generated caption: a photo with many details showing broccoli in bins, - the. on … food park big confines a large two three and busted zoo fr herd blue tie field cat spot an nearᅯ gi angeles ocean tower leaned lightedgong dogն softer o giant green & person vittorio ridingიր some œ pet silk chiկյ neck deserts itտ black number grazing man goldminated grassy designer pedestriansս
INFO:__main__:Model saved to models/vlm/gen_4_baseline
INFO:__main__:Training generation 5
INFO:__main__:Using checkpoint from models/vlm/gen_4_baseline
INFO:__main__:Found 100 images for training
INFO:__main__:Loaded 414113 captions from data/coco/annotations/captions_train2014.json
INFO:__main__:Found 100 images in data/vlm/train/images/real
INFO:__main__:Created dataset with 100 image-caption pairs for gen_5 using baseline mode
INFO:__main__:Using all 100 images for training in gen_5 with baseline mode
INFO:__main__:Loading model with aggressive memory optimizations
INFO:accelerate.utils.modeling:We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
INFO:__main__:Starting training for generation 5 with 10 epochs in baseline mode
  0%|                                                                                               | 0/60 [00:00<?, ?it/s]C:\Users\zizha\anaconda3\envs\311\Lib\site-packages\torch\utils\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]


 18%|███████████████▊                                                                      | 11/60 [00:06<00:27,  1.76it/s]


 30%|█████████████████████████▊                                                            | 18/60 [00:09<00:24,  1.74it/s]



 52%|████████████████████████████████████████████▍                                         | 31/60 [00:16<00:14,  2.02it/s]


 65%|███████████████████████████████████████████████████████▉                              | 39/60 [00:20<00:10,  1.98it/s]


 78%|███████████████████████████████████████████████████████████████████▎                  | 47/60 [00:24<00:06,  1.93it/s]


100%|██████████████████████████████████████████████████████████████████████████████████████| 60/60 [00:30<00:00,  1.97it/s]
INFO:__main__:Training completed successfully
INFO:__main__:Saving model
{'loss': 0.0029, 'grad_norm': 0.08017659187316895, 'learning_rate': 0.0, 'epoch': 8.64}
{'train_runtime': 30.3855, 'train_samples_per_second': 32.91, 'train_steps_per_second': 1.975, 'train_loss': 0.008594201846669118, 'epoch': 8.64}
INFO:__main__:Generating caption for the first training image to evaluate the model
Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.
C:\Users\zizha\anaconda3\envs\311\Lib\site-packages\torch\utils\checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
INFO:__main__:Original caption: Closeup of bins of food that include broccoli and bread.
INFO:__main__:Generated caption: a comprehensive image depicting bins of food that include broccoli, bread, and bread. in a bright green field. the.
INFO:__main__:Model saved to models/vlm/gen_5_baseline
INFO:__main__:Training generation 6
INFO:__main__:Using checkpoint from models/vlm/gen_5_baseline
INFO:__main__:Found 100 images for training
INFO:__main__:Loaded 414113 captions from data/coco/annotations/captions_train2014.json
INFO:__main__:Found 100 images in data/vlm/train/images/real
INFO:__main__:Created dataset with 100 image-caption pairs for gen_6 using baseline mode
INFO:__main__:Using all 100 images for training in gen_6 with baseline mode
INFO:__main__:Loading model with aggressive memory optimizations
INFO:accelerate.utils.modeling:We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
INFO:__main__:Starting training for generation 6 with 10 epochs in baseline mode
  0%|                                                                                               | 0/60 [00:00<?, ?it/s]C:\Users\zizha\anaconda3\envs\311\Lib\site-packages\torch\utils\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]


 18%|███████████████▊                                                                      | 11/60 [00:05<00:25,  1.94it/s]


 32%|███████████████████████████▏                                                          | 19/60 [00:09<00:22,  1.86it/s]



 50%|███████████████████████████████████████████                                           | 30/60 [00:15<00:15,  1.96it/s]


 63%|██████████████████████████████████████████████████████▍                               | 38/60 [00:19<00:12,  1.83it/s]



 83%|███████████████████████████████████████████████████████████████████████▋              | 50/60 [00:25<00:04,  2.06it/s]


100%|██████████████████████████████████████████████████████████████████████████████████████| 60/60 [00:31<00:00,  1.93it/s]
INFO:__main__:Training completed successfully
INFO:__main__:Saving model
INFO:__main__:Generating caption for the first training image to evaluate the model
Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.
C:\Users\zizha\anaconda3\envs\311\Lib\site-packages\torch\utils\checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
{'loss': 0.0008, 'grad_norm': 0.022217119112610817, 'learning_rate': 0.0, 'epoch': 8.64}
{'train_runtime': 31.0856, 'train_samples_per_second': 32.169, 'train_steps_per_second': 1.93, 'train_loss': 0.003464606124907732, 'epoch': 8.64}
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
INFO:__main__:Original caption: Closeup of bins of food that include broccoli and bread.
INFO:__main__:Generated caption: a detailed scene showing bins of food that include broccoli, bread and bread on a sunny day in the.. big.
INFO:__main__:Model saved to models/vlm/gen_6_baseline
INFO:__main__:Training generation 7
INFO:__main__:Using checkpoint from models/vlm/gen_6_baseline
INFO:__main__:Found 100 images for training
INFO:__main__:Loaded 414113 captions from data/coco/annotations/captions_train2014.json
INFO:__main__:Found 100 images in data/vlm/train/images/real
INFO:__main__:Created dataset with 100 image-caption pairs for gen_7 using baseline mode
INFO:__main__:Using all 100 images for training in gen_7 with baseline mode
INFO:__main__:Loading model with aggressive memory optimizations
INFO:accelerate.utils.modeling:We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
INFO:__main__:Starting training for generation 7 with 10 epochs in baseline mode
  0%|                                                                                               | 0/60 [00:00<?, ?it/s]C:\Users\zizha\anaconda3\envs\311\Lib\site-packages\torch\utils\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]


 18%|███████████████▊                                                                      | 11/60 [00:06<00:26,  1.84it/s]


 32%|███████████████████████████▏                                                          | 19/60 [00:10<00:21,  1.89it/s]



 52%|████████████████████████████████████████████▍                                         | 31/60 [00:15<00:14,  2.01it/s]


 67%|█████████████████████████████████████████████████████████▎                            | 40/60 [00:20<00:10,  1.92it/s]


 80%|████████████████████████████████████████████████████████████████████▊                 | 48/60 [00:24<00:06,  1.90it/s]


100%|██████████████████████████████████████████████████████████████████████████████████████| 60/60 [00:29<00:00,  2.01it/s]
INFO:__main__:Training completed successfully
INFO:__main__:Saving model
{'loss': 0.0003, 'grad_norm': 0.011799199506640434, 'learning_rate': 0.0, 'epoch': 8.64}
{'train_runtime': 29.8921, 'train_samples_per_second': 33.454, 'train_steps_per_second': 2.007, 'train_loss': 0.002626399913181861, 'epoch': 8.64}
INFO:__main__:Generating caption for the first training image to evaluate the model
Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.
C:\Users\zizha\anaconda3\envs\311\Lib\site-packages\torch\utils\checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
INFO:__main__:Original caption: Closeup of bins of food that include broccoli and bread.
INFO:__main__:Generated caption: a detailed scene showing some bins of food that include broccoli and bread. -, in the on big...
INFO:__main__:Model saved to models/vlm/gen_7_baseline
INFO:__main__:Training generation 8
INFO:__main__:Using checkpoint from models/vlm/gen_7_baseline
INFO:__main__:Found 100 images for training
INFO:__main__:Loaded 414113 captions from data/coco/annotations/captions_train2014.json
INFO:__main__:Found 100 images in data/vlm/train/images/real
INFO:__main__:Created dataset with 100 image-caption pairs for gen_8 using baseline mode
INFO:__main__:Using all 100 images for training in gen_8 with baseline mode
INFO:__main__:Loading model with aggressive memory optimizations
INFO:accelerate.utils.modeling:We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
INFO:__main__:Starting training for generation 8 with 10 epochs in baseline mode
  0%|                                                                                               | 0/60 [00:00<?, ?it/s]C:\Users\zizha\anaconda3\envs\311\Lib\site-packages\torch\utils\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]


 18%|███████████████▊                                                                      | 11/60 [00:05<00:25,  1.94it/s]


 32%|███████████████████████████▏                                                          | 19/60 [00:09<00:21,  1.94it/s]


 47%|████████████████████████████████████████▏                                             | 28/60 [00:13<00:12,  2.47it/s]



 67%|█████████████████████████████████████████████████████████▎                            | 40/60 [00:19<00:10,  1.94it/s]


 82%|██████████████████████████████████████████████████████████████████████▏               | 49/60 [00:23<00:04,  2.48it/s]


100%|██████████████████████████████████████████████████████████████████████████████████████| 60/60 [00:29<00:00,  2.05it/s]
INFO:__main__:Training completed successfully
INFO:__main__:Saving model
INFO:__main__:Generating caption for the first training image to evaluate the model
Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.
C:\Users\zizha\anaconda3\envs\311\Lib\site-packages\torch\utils\checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
{'loss': 0.0001, 'grad_norm': 0.0026560486294329166, 'learning_rate': 0.0, 'epoch': 8.64}
{'train_runtime': 29.2531, 'train_samples_per_second': 34.184, 'train_steps_per_second': 2.051, 'train_loss': 0.0008482515967140595, 'epoch': 8.64}
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
INFO:__main__:Original caption: Closeup of bins of food that include broccoli and bread.
INFO:__main__:Generated caption: a detailed scene showing some kind of food that is in a bin. for a woman ' s day. the a large white.
INFO:__main__:Model saved to models/vlm/gen_8_baseline
INFO:__main__:Training generation 9
INFO:__main__:Using checkpoint from models/vlm/gen_8_baseline
INFO:__main__:Found 100 images for training
INFO:__main__:Loaded 414113 captions from data/coco/annotations/captions_train2014.json
INFO:__main__:Found 100 images in data/vlm/train/images/real
INFO:__main__:Created dataset with 100 image-caption pairs for gen_9 using baseline mode
INFO:__main__:Using all 100 images for training in gen_9 with baseline mode
INFO:__main__:Loading model with aggressive memory optimizations
INFO:accelerate.utils.modeling:We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
INFO:__main__:Starting training for generation 9 with 10 epochs in baseline mode
  0%|                                                                                               | 0/60 [00:00<?, ?it/s]C:\Users\zizha\anaconda3\envs\311\Lib\site-packages\torch\utils\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]

 13%|███████████▌                                                                           | 8/60 [00:04<00:23,  2.19it/s]



 35%|██████████████████████████████                                                        | 21/60 [00:10<00:15,  2.47it/s]


 48%|█████████████████████████████████████████▌                                            | 29/60 [00:14<00:13,  2.22it/s]



 70%|████████████████████████████████████████████████████████████▏                         | 42/60 [00:20<00:07,  2.47it/s]


 83%|███████████████████████████████████████████████████████████████████████▋              | 50/60 [00:24<00:04,  2.22it/s]


 97%|███████████████████████████████████████████████████████████████████████████████████▏  | 58/60 [00:28<00:00,  2.10it/s]
{'loss': 0.0001, 'grad_norm': 0.0032469877041876316, 'learning_rate': 0.0, 'epoch': 8.64}
100%|██████████████████████████████████████████████████████████████████████████████████████| 60/60 [00:29<00:00,  2.05it/s]
INFO:__main__:Training completed successfully
INFO:__main__:Saving model
INFO:__main__:Generating caption for the first training image to evaluate the model
Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.
C:\Users\zizha\anaconda3\envs\311\Lib\site-packages\torch\utils\checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
INFO:__main__:Original caption: Closeup of bins of food that include broccoli and bread.
INFO:__main__:Generated caption: a detailed scene showing bins of food that include broccoli and bread. for a variety of colors in a street. on
INFO:__main__:Model saved to models/vlm/gen_9_baseline
INFO:__main__:Training generation 10
INFO:__main__:Using checkpoint from models/vlm/gen_9_baseline
INFO:__main__:Found 100 images for training
INFO:__main__:Loaded 414113 captions from data/coco/annotations/captions_train2014.json
INFO:__main__:Found 100 images in data/vlm/train/images/real
INFO:__main__:Created dataset with 100 image-caption pairs for gen_10 using baseline mode
INFO:__main__:Using all 100 images for training in gen_10 with baseline mode
INFO:__main__:Loading model with aggressive memory optimizations
INFO:accelerate.utils.modeling:We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
INFO:__main__:Starting training for generation 10 with 10 epochs in baseline mode
  0%|                                                                                               | 0/60 [00:00<?, ?it/s]C:\Users\zizha\anaconda3\envs\311\Lib\site-packages\torch\utils\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]


 13%|███████████▌                                                                           | 8/60 [00:04<00:25,  2.01it/s]



 32%|███████████████████████████▏                                                          | 19/60 [00:10<00:23,  1.78it/s]



 52%|████████████████████████████████████████████▍                                         | 31/60 [00:16<00:15,  1.89it/s]


 65%|███████████████████████████████████████████████████████▉                              | 39/60 [00:20<00:11,  1.81it/s]



 85%|█████████████████████████████████████████████████████████████████████████             | 51/60 [00:26<00:04,  1.96it/s]


 98%|████████████████████████████████████████████████████████████████████████████████████▌ | 59/60 [00:30<00:00,  1.97it/s]
{'loss': 0.0, 'grad_norm': 0.0034304566215723753, 'learning_rate': 0.0, 'epoch': 8.64}
100%|██████████████████████████████████████████████████████████████████████████████████████| 60/60 [00:31<00:00,  1.93it/s]
INFO:__main__:Training completed successfully
INFO:__main__:Saving model
INFO:__main__:Generating caption for the first training image to evaluate the model
Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.
C:\Users\zizha\anaconda3\envs\311\Lib\site-packages\torch\utils\checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
INFO:__main__:Original caption: Closeup of bins of food that include broccoli and bread.
INFO:__main__:Generated caption: a detailed scene showing some of the food in the bins. for a big group of people ' s food. -.fe..
INFO:__main__:Model saved to models/vlm/gen_10_baseline
INFO:__main__:Training completed through generation 10
INFO:__main__:Final model saved at: models/vlm/gen_10_baseline